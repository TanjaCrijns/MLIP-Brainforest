{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Primary & Blooming Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using Theano backend.\n",
      "Using cuDNN version 5110 on context None\n",
      "Mapped name None to device cuda0: GeForce GTX 1050 Ti (0000:09:00.0)\n"
     ]
    }
   ],
   "source": [
    "from keras.models import Sequential, load_model, Model\n",
    "from keras.layers import Conv2D, Dense, Flatten, Dropout, MaxPooling2D, BatchNormalization\n",
    "from keras.optimizers import Adam, SGD\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.callbacks import CSVLogger, ModelCheckpoint, ReduceLROnPlateau\n",
    "from keras.applications.vgg16 import VGG16, preprocess_input\n",
    "\n",
    "import numpy as np\n",
    "import cPickle as pickle\n",
    "import pandas as pd\n",
    "import cv2\n",
    "from PIL import Image\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import glob\n",
    "import os\n",
    "import sys\n",
    "sys.path.insert(0, '..')\n",
    "import paths\n",
    "sys.path.insert(0, '../rainforest')\n",
    "import data\n",
    "import data_generators_leo as dgl"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load training data and labels."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(28335,)\n",
      "(12144,)\n",
      "(28335, 1)\n",
      "(12144, 1)\n"
     ]
    }
   ],
   "source": [
    "batch_size = 32\n",
    "size_img = 92\n",
    "imgs = (size_img,size_img)\n",
    "#train_csv = data.get_class_data(train=True, label='primary')\n",
    "\n",
    "#label is blooming\n",
    "\n",
    "train_csv =np.asarray(data.get_data(train=True)) #everything in onehot\n",
    "val_csv = np.asarray(data.get_data(train=False)) #everything in onehot\n",
    "\n",
    "train_data = train_csv[:,0] #image names training\n",
    "val_data = val_csv[:,0] #image names validation\n",
    "\n",
    "#train_labels = train_csv[:,2:3] #blooming\n",
    "#val_labels = val_csv[:,2:3]\n",
    "train_labels = train_csv[:,11:12] #primary\n",
    "val_labels = val_csv[:,2:3]\n",
    "\n",
    "print train_data.shape\n",
    "print val_data.shape\n",
    "print train_labels.shape\n",
    "print val_labels.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(28335, 2)\n",
      "(12144, 2)\n"
     ]
    }
   ],
   "source": [
    "dim = len(train_labels)\n",
    "dimlabel = np.zeros((dim, 2))\n",
    "for i, j in zip(train_labels, dimlabel):\n",
    "    j[i[0]] = 1\n",
    "train_labels = dimlabel\n",
    "\n",
    "dim = len(val_labels)\n",
    "vallabel = np.zeros((dim, 2))\n",
    "for i, j in zip(val_labels, vallabel):\n",
    "    j[i[0]] = 1\n",
    "val_labels = vallabel\n",
    "print train_labels.shape\n",
    "print val_labels.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generators"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_gen = dgl.get_data(train_data, '../data/train-jpg', train_labels, batch_size=batch_size, img_size=imgs, balance_batches=True, augmentation=True, hflip=True, vflip=True, shift_x=5, shift_y=5, rot_range=10)\n",
    "\n",
    "val_gen = dgl.get_data(val_data, '../data/train-jpg', val_labels, batch_size=batch_size, img_size=imgs, balance_batches=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "#imgs, labels = train_gen.next()\n",
    "\n",
    "#for img, label in zip(imgs, labels):\n",
    "#    print label"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Network Structure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_1 (Conv2D)            (None, 16, 90, 90)        448       \n",
      "_________________________________________________________________\n",
      "conv2d_2 (Conv2D)            (None, 16, 88, 88)        2320      \n",
      "_________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2 (None, 16, 44, 44)        0         \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 16, 44, 44)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_3 (Conv2D)            (None, 32, 42, 42)        4640      \n",
      "_________________________________________________________________\n",
      "conv2d_4 (Conv2D)            (None, 32, 40, 40)        9248      \n",
      "_________________________________________________________________\n",
      "max_pooling2d_2 (MaxPooling2 (None, 32, 20, 20)        0         \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 32, 20, 20)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_5 (Conv2D)            (None, 64, 18, 18)        18496     \n",
      "_________________________________________________________________\n",
      "conv2d_6 (Conv2D)            (None, 64, 16, 16)        36928     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_3 (MaxPooling2 (None, 64, 8, 8)          0         \n",
      "_________________________________________________________________\n",
      "dropout_3 (Dropout)          (None, 64, 8, 8)          0         \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 4096)              0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 256)               1048832   \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 2)                 514       \n",
      "=================================================================\n",
      "Total params: 1,121,426.0\n",
      "Trainable params: 1,121,426.0\n",
      "Non-trainable params: 0.0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "\n",
    "model = Sequential()\n",
    "\n",
    "model.add(Conv2D(16, (3, 3), activation='relu', input_shape=(3, 92, 92)))\n",
    "model.add(Conv2D(16, (3, 3), activation='relu'))\n",
    "model.add(MaxPooling2D())\n",
    "model.add(Dropout(0.25))\n",
    "\n",
    "model.add(Conv2D(32, (3, 3), activation='relu'))\n",
    "model.add(Conv2D(32, (3, 3), activation='relu'))\n",
    "model.add(MaxPooling2D())\n",
    "model.add(Dropout(0.25))\n",
    "\n",
    "model.add(Conv2D(64, (3, 3), activation='relu'))\n",
    "model.add(Conv2D(64, (3, 3), activation='relu'))\n",
    "model.add(MaxPooling2D())\n",
    "model.add(Dropout(0.25))\n",
    "\n",
    "model.add(Flatten())\n",
    "model.add(Dense(256))\n",
    "model.add(Dense(2, activation='softmax'))\n",
    "\n",
    "\n",
    "model.compile(optimizer='Adam', loss='binary_crossentropy',metrics=['accuracy'])\n",
    "model.summary()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "885\n",
      "379\n",
      "Epoch 1/10\n",
      "884/885 [============================>.] - ETA: 0s - loss: 0.6903 - acc: 0.5234Epoch 00000: val_loss improved from inf to 0.69041, saving model to /home/pieter/projects/MLIP-Brainforest/bloomingtest/VGG/model.00-0.69.hdf5\n",
      "885/885 [==============================] - 73s - loss: 0.6903 - acc: 0.5233 - val_loss: 0.6904 - val_acc: 0.6005\n",
      "Epoch 2/10\n",
      "884/885 [============================>.] - ETA: 0s - loss: 0.6932 - acc: 0.5026Epoch 00001: val_loss did not improve\n",
      "885/885 [==============================] - 70s - loss: 0.6932 - acc: 0.5026 - val_loss: 0.6931 - val_acc: 0.5000\n",
      "Epoch 3/10\n",
      "884/885 [============================>.] - ETA: 0s - loss: 0.6931 - acc: 0.5000\n",
      "Epoch 00002: reducing learning rate to 0.000500000023749.\n",
      "Epoch 00002: val_loss did not improve\n",
      "885/885 [==============================] - 70s - loss: 0.6931 - acc: 0.5000 - val_loss: 0.6931 - val_acc: 0.5000\n",
      "Epoch 4/10\n",
      "884/885 [============================>.] - ETA: 0s - loss: 0.6931 - acc: 0.4997\n",
      "Epoch 00003: reducing learning rate to 0.000250000011874.\n",
      "Epoch 00003: val_loss did not improve\n",
      "885/885 [==============================] - 71s - loss: 0.6931 - acc: 0.4997 - val_loss: 0.6931 - val_acc: 0.5000\n",
      "Epoch 5/10\n",
      "884/885 [============================>.] - ETA: 0s - loss: 0.6931 - acc: 0.4999\n",
      "Epoch 00004: reducing learning rate to 0.000125000005937.\n",
      "Epoch 00004: val_loss did not improve\n",
      "885/885 [==============================] - 71s - loss: 0.6931 - acc: 0.4999 - val_loss: 0.6931 - val_acc: 0.5000\n",
      "Epoch 6/10\n",
      "884/885 [============================>.] - ETA: 0s - loss: 0.6931 - acc: 0.4999\n",
      "Epoch 00005: reducing learning rate to 6.25000029686e-05.\n",
      "Epoch 00005: val_loss did not improve\n",
      "885/885 [==============================] - 70s - loss: 0.6931 - acc: 0.4999 - val_loss: 0.6931 - val_acc: 0.5000\n",
      "Epoch 7/10\n",
      "884/885 [============================>.] - ETA: 0s - loss: 0.6931 - acc: 0.5001\n",
      "Epoch 00006: reducing learning rate to 3.12500014843e-05.\n",
      "Epoch 00006: val_loss did not improve\n",
      "885/885 [==============================] - 71s - loss: 0.6931 - acc: 0.5001 - val_loss: 0.6931 - val_acc: 0.5000\n",
      "Epoch 8/10\n",
      "884/885 [============================>.] - ETA: 0s - loss: 0.6931 - acc: 0.4999\n",
      "Epoch 00007: reducing learning rate to 1.56250007421e-05.\n",
      "Epoch 00007: val_loss did not improve\n",
      "885/885 [==============================] - 71s - loss: 0.6931 - acc: 0.4999 - val_loss: 0.6931 - val_acc: 0.5000\n",
      "Epoch 9/10\n",
      "884/885 [============================>.] - ETA: 0s - loss: 0.6931 - acc: 0.5000\n",
      "Epoch 00008: reducing learning rate to 7.81250037107e-06.\n",
      "Epoch 00008: val_loss did not improve\n",
      "885/885 [==============================] - 71s - loss: 0.6931 - acc: 0.5000 - val_loss: 0.6931 - val_acc: 0.5000\n",
      "Epoch 10/10\n",
      "884/885 [============================>.] - ETA: 0s - loss: 0.6931 - acc: 0.5001\n",
      "Epoch 00009: reducing learning rate to 3.90625018554e-06.\n",
      "Epoch 00009: val_loss did not improve\n",
      "885/885 [==============================] - 69s - loss: 0.6931 - acc: 0.5001 - val_loss: 0.6931 - val_acc: 0.5000\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7fa6987053d0>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "steps = len(train_data)/batch_size\n",
    "steps_val = len(val_data)/batch_size\n",
    "print steps\n",
    "print steps_val\n",
    "\n",
    "\n",
    "csv_logger = CSVLogger('run4_adam.csv')\n",
    "lr_plateau = ReduceLROnPlateau(monitor='val_loss', patience=1, verbose=1, factor=0.5)\n",
    "checkpoint = ModelCheckpoint(filepath='/home/pieter/projects/MLIP-Brainforest/bloomingtest/VGG/model.{epoch:02d}-{val_loss:.2f}.hdf5',\n",
    "                             verbose=1, save_best_only=True)\n",
    "\n",
    "model.fit_generator(train_gen, steps_per_epoch=steps,\n",
    "                    epochs=10, verbose=1,\n",
    "                    callbacks=[csv_logger, lr_plateau, checkpoint],\n",
    "                    validation_data=val_gen, validation_steps=steps_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2 MLIP Keras Theano",
   "language": "python",
   "name": "mlippython2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
