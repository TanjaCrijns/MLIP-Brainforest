{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Primary vs Primary + Blooming"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this notebook all the images with the label primary (but not blooming) will be put against images with the label primary and blooming. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using Theano backend.\n",
      "Using cuDNN version 5110 on context None\n",
      "Mapped name None to device cuda0: GeForce GTX 1050 Ti (0000:09:00.0)\n"
     ]
    }
   ],
   "source": [
    "from keras.models import Sequential, load_model, Model\n",
    "from keras.layers import Conv2D, Dense, Flatten, Dropout, MaxPooling2D, BatchNormalization\n",
    "from keras.optimizers import Adam, SGD\n",
    "from keras.callbacks import CSVLogger, ModelCheckpoint, ReduceLROnPlateau\n",
    "\n",
    "import numpy as np\n",
    "import cPickle as pickle\n",
    "import pandas as pd\n",
    "import glob\n",
    "import os\n",
    "import sys\n",
    "sys.path.insert(0, '..')\n",
    "import paths\n",
    "sys.path.insert(0, '../rainforest')\n",
    "import data\n",
    "import data_generators_leo as dgl"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loading training data and corresponding labels. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Images = ['image_name', 'primary', 'blooming']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(26284, 2)\n",
      "(11229, 2)\n"
     ]
    }
   ],
   "source": [
    "batch_size = 64\n",
    "size_img = 64\n",
    "imgs = (size_img,size_img)\n",
    "#train_csv = data.get_class_data(train=True, label='primary')\n",
    "\n",
    "#label is blooming\n",
    "\n",
    "train_csv = np.asarray(data.get_class_data(train=True, label='primary')) #everything in onehot\n",
    "val_csv =  np.asarray(data.get_class_data(train=False, label='primary')) #everything in onehot\n",
    "\n",
    "train_data = []\n",
    "for i in train_csv:\n",
    "    if i[1] == 1:\n",
    "        appending = [i[0], int(i[1]), int(i[2])]\n",
    "        train_data.append(appending)\n",
    "train_csv = np.asarray(train_data)\n",
    "\n",
    "val_data = []\n",
    "for i in val_csv:\n",
    "    if i[1] == 1:\n",
    "        appending = [i[0], int(i[1]), int(i[2])]\n",
    "        val_data.append(appending)\n",
    "val_csv = np.asarray(val_data)\n",
    "\n",
    "\n",
    "train_data = train_csv[:,0] #image names training\n",
    "val_data = val_csv[:,0] #image names validation\n",
    "\n",
    "\n",
    "train_labels = train_csv[:,1:] \n",
    "val_labels = val_csv[:,1:]\n",
    "\n",
    "print train_labels.shape\n",
    "print val_labels.shape\n",
    "\n",
    "#train_labels = train_csv[:,11:12] #primary\n",
    "#val_labels = val_csv[:,2:3]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "dim = len(train_labels)\n",
    "dimlabel = np.zeros((dim, 2))\n",
    "\n",
    "for i, j in zip(dimlabel, train_labels[:,1]):\n",
    "    i[0] = 1\n",
    "    i[1] = j[0]\n",
    "\n",
    "train_labels = dimlabel\n",
    "\n",
    "dim = len(val_labels)\n",
    "dimlabel = np.zeros((dim, 2))\n",
    "for i, j in zip(dimlabel, val_labels[:,1]):\n",
    "    i[0] = 1\n",
    "    i[1] = j[0]\n",
    "\n",
    "val_labels = dimlabel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(26284, 2)\n",
      "(11229, 2)\n",
      "(11229,)\n",
      "(26284,)\n",
      "[ 1.  0.]\n",
      "[ 1.  0.]\n",
      "train_8337\n",
      "train_19035\n"
     ]
    }
   ],
   "source": [
    "print train_labels.shape\n",
    "print val_labels.shape\n",
    "print val_data.shape\n",
    "print train_data.shape\n",
    "\n",
    "print train_labels[1]\n",
    "print val_labels[1]\n",
    "print train_data[1]\n",
    "print val_data[1]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Generators"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_gen = dgl.get_data(train_data, '../data/train-jpg', train_labels, batch_size=batch_size, img_size=imgs, balance_batches=True, augmentation=True, hflip=True, vflip=True, shift_x=5, shift_y=5, rot_range=10)\n",
    "val_gen = dgl.get_data(val_data, '../data/train-jpg', val_labels, batch_size=batch_size, img_size=imgs, balance_batches=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "a, b = train_gen.next()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Network Structure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "\n",
    "model.add(Conv2D(16, (3, 3), activation='relu', input_shape=(3, 64, 64)))\n",
    "model.add(Conv2D(16, (3, 3), activation='relu'))\n",
    "model.add(MaxPooling2D())\n",
    "model.add(Dropout(0.25))\n",
    "\n",
    "model.add(Conv2D(32, (3, 3), activation='relu'))\n",
    "model.add(Conv2D(32, (3, 3), activation='relu'))\n",
    "model.add(MaxPooling2D())\n",
    "model.add(Dropout(0.25))\n",
    "\n",
    "model.add(Conv2D(64, (3, 3), activation='relu'))\n",
    "model.add(Conv2D(64, (3, 3), activation='relu'))\n",
    "model.add(MaxPooling2D())\n",
    "model.add(Dropout(0.25))\n",
    "\n",
    "model.add(Flatten())\n",
    "model.add(Dense(256))\n",
    "model.add(Dense(2, activation='softmax'))\n",
    "\n",
    "\n",
    "model.compile(optimizer='Adam', loss='binary_crossentropy',metrics=['accuracy'])\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "steps = len(train_data)/batch_size\n",
    "steps_val = len(val_data)/batch_size\n",
    "print steps\n",
    "print steps_val\n",
    "\n",
    "\n",
    "csv_logger = CSVLogger('run4_adam.csv')\n",
    "lr_plateau = ReduceLROnPlateau(monitor='val_loss', patience=1, verbose=1, factor=0.5)\n",
    "checkpoint = ModelCheckpoint(filepath='/home/pieter/projects/MLIP-Brainforest/bloomingtest/OWN/model.{epoch:02d}-{val_loss:.2f}.hdf5',\n",
    "                             verbose=1, save_best_only=True)\n",
    "\n",
    "model.fit_generator(train_gen, steps_per_epoch=steps,\n",
    "                    epochs=10, verbose=1,\n",
    "                    callbacks=[csv_logger, lr_plateau, checkpoint],\n",
    "                    validation_data=val_gen, validation_steps=steps_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2 MLIP Keras Theano",
   "language": "python",
   "name": "mlippython2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
