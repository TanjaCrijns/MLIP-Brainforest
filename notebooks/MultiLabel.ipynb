{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import sys\n",
    "sys.path.append('..')\n",
    "\n",
    "from spectral import get_rgb, ndvi\n",
    "import glob\n",
    "import os\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "from sklearn.metrics import fbeta_score\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from skimage.io import imread\n",
    "\n",
    "from keras.models import Sequential\n",
    "from keras.layers import *\n",
    "from keras.callbacks import CSVLogger, ReduceLROnPlateau, ModelCheckpoint\n",
    "from keras import backend as K\n",
    "import paths\n",
    "\n",
    "from rainforest.data import get_data, labels\n",
    "from rainforest.preprocess import preprocess\n",
    "from rainforest.models.resnet import ResNet50\n",
    "from rainforest.models.densenet import create_dense_net"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_data = get_data(train=True)\n",
    "val_data = get_data(train=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "batch_size=32\n",
    "input_size=(64, 64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def preprocess_image1(img):\n",
    "    img_rgb = get_rgb(img, [2, 1, 0])  # R-G-B\n",
    "    rescaleimg = np.reshape(img_rgb, (-1, 1))\n",
    "    scaler = MinMaxScaler(feature_range=(0, 255))\n",
    "    rescaleimg = scaler.fit_transform(rescaleimg)  # .astype(np.float32)\n",
    "    img_scaled = (np.reshape(rescaleimg, img_rgb.shape)) / 255.\n",
    "    img_scaled = img_scaled.transpose(2,0,1)\n",
    "    img_nir = get_rgb(img, [3, 2, 1])  # NIR-R-G\n",
    "    img_nir_red = (img_nir[:, :, 0] - img_nir[:, :, 1]) / (img_nir[:, :, 0] + img_nir[:, :, 1] + np.finfo(float).eps)  # (NIR - RED) / (NIR + RED)\n",
    "    img_nir_red = np.expand_dims(np.clip(img_nir_red, -1, 1), axis=0)\n",
    "    img_nir_green = (img_nir[:, :, 2] - img_nir[:, :, 0]) / (img_nir[:, :, 2] + img_nir[:, :, 0] + np.finfo(float).eps)  # (GREEN - NIR) / (GREEN + NIR)\n",
    "    img_nir_green = np.expand_dims(np.clip(img_nir_green, -1, 1), axis=0)\n",
    "\n",
    "    return np.concatenate((img_scaled, img_nir_red, img_nir_green), axis=0).transpose(1, 2, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def data_generator(data_df, batch_size=32, target_size=(256, 256), shuffle=True, augmentation=True, subfolder='train-jpg',\n",
    "                  extension='jpg'):\n",
    "    n = len(data_df)\n",
    "    while True:\n",
    "        # Maybe shuffle\n",
    "        data = data_df.sample(frac=1) if shuffle else data_df\n",
    "        data = data.append(data, ignore_index=True)\n",
    "        i = 0\n",
    "        while i < n:\n",
    "            X_batch = np.zeros((batch_size, target_size[0], target_size[1], 5) , dtype=np.float32)\n",
    "            y_batch = np.zeros((batch_size, 17), dtype=np.uint8)\n",
    "            \n",
    "            for j in range(batch_size):\n",
    "                img = data.iloc[i]\n",
    "                img_path = os.path.join(paths.DATA_FOLDER, subfolder, img.image_name+'.'+extension)\n",
    "                image = imread(img_path)\n",
    "                image = preprocess_image1(image)\n",
    "                image = preprocess(image, target_size=target_size, augmentation=augmentation,\n",
    "                           hflip=True, vflip=True, shift_x=3, shift_y=3, rot_range=5)\n",
    "                image = np.transpose(image, (1, 2, 0))\n",
    "                X_batch[j] = image\n",
    "                y_batch[j] = img[1:].values\n",
    "                i += 1\n",
    "            \n",
    "            yield X_batch, y_batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def fb_score(beta=1, smooth=1e-6, threshold=0.2):\n",
    "    \n",
    "    def fscore(y_true, y_pred):\n",
    "        y_pred = y_pred > threshold\n",
    "        recall = (K.sum(y_true * y_pred, axis=1) + smooth) / (K.sum(y_true, axis=1) + smooth)\n",
    "        precision = (K.sum(y_true * y_pred, axis=1) + smooth) / (K.sum(y_pred, axis=1) + smooth)\n",
    "        return K.mean( ((1+beta**2) * (precision*recall)+smooth) / (beta**2*precision+recall+smooth) )\n",
    "    \n",
    "    fscore.__name__ = 'F%d_score' % beta\n",
    "    \n",
    "    return fscore"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def resnet_like():\n",
    "    model = ResNet50(input_shape=(64, 64, 3), classes=17, classification='sigmoid', layer1_filters=32)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def vgg_like():\n",
    "    model = Sequential([\n",
    "        Conv2D(32, 3, activation='relu', kernel_initializer='he_normal', input_shape=(3,)+input_size),\n",
    "        BatchNormalization(axis=1),\n",
    "        Conv2D(32, 3, activation='relu', kernel_initializer='he_normal'),\n",
    "        BatchNormalization(axis=1),\n",
    "        MaxPool2D(),\n",
    "\n",
    "        Conv2D(64, 3, activation='relu', kernel_initializer='he_normal'),\n",
    "        BatchNormalization(axis=1),\n",
    "        Conv2D(64, 3, activation='relu', kernel_initializer='he_normal'),\n",
    "        BatchNormalization(axis=1),\n",
    "        MaxPool2D(),\n",
    "\n",
    "        Conv2D(128, 3, activation='relu', kernel_initializer='he_normal'),\n",
    "        BatchNormalization(axis=1),\n",
    "        Conv2D(128, 3, activation='relu', kernel_initializer='he_normal'),\n",
    "        BatchNormalization(axis=1),\n",
    "        MaxPool2D(),\n",
    "\n",
    "        Flatten(),\n",
    "        Dense(1024, activation='relu', kernel_initializer='he_normal'),\n",
    "        BatchNormalization(),\n",
    "        Dense(17, activation='sigmoid')\n",
    "    ])\n",
    "    \n",
    "    return model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = create_dense_net(17, (64, 64, 5), weight_decay=0)\n",
    "\n",
    "model.summary()\n",
    "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy', fb_score(beta=2)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_gen = data_generator(train_data, batch_size=batch_size, target_size=input_size, shuffle=True, augmentation=True,\n",
    "                           extension='tif', subfolder='train-tif-v2')\n",
    "val_gen = data_generator(val_data, batch_size=batch_size, target_size=input_size, shuffle=False, augmentation=False,\n",
    "                        extension='tif', subfolder='train-tif-v2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "csv_logger = CSVLogger('log.csv')\n",
    "lr_plateau = ReduceLROnPlateau(monitor='val_loss', patience=3, verbose=1, factor=0.25)\n",
    "checkpoint = ModelCheckpoint(filepath='E:/Models/brainforest/densenet_64x64_tif.hdf5', verbose=1, save_best_only=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "train_steps = len(train_data) // batch_size\n",
    "val_steps = len(val_data) // batch_size\n",
    "model.fit_generator(train_gen, train_steps, epochs=50, callbacks=[csv_logger, lr_plateau, checkpoint],\n",
    "                    validation_data=val_gen, validation_steps=val_steps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model.load_weights('E:/Models/brainforest/resnet16_64x64.hdf5')\n",
    "\n",
    "def strip_labels(gen):\n",
    "    while True:\n",
    "        imgs, _ = next(gen)\n",
    "        yield imgs\n",
    "\n",
    "val_steps = int(np.ceil(len(val_data) // batch_size)) + 1\n",
    "val_gen = strip_labels(data_generator(val_data, batch_size=batch_size, target_size=input_size, shuffle=False))\n",
    "preds = model.predict_generator(val_gen, val_steps)\n",
    "preds = preds[:len(val_data)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for threshold in np.arange(0.1, 0.3, 0.02):\n",
    "    y_true = val_data.iloc[:, 1:].values\n",
    "    y_pred =  preds > threshold\n",
    "    print threshold, 'f2 score:', fbeta_score(y_true, y_pred, 2, average='samples')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "test_files = glob.glob(os.path.join(paths.DATA_FOLDER, 'test-jpg', '*.jpg'))\n",
    "test_files = [os.path.basename(os.path.splitext(f)[0]) for f in test_files]\n",
    "test_data = pd.DataFrame(test_files, columns=['image_name'])\n",
    "test_data['bogus_label'] = np.zeros(len(test_files))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "test_steps = int(np.ceil(len(test_data) // batch_size)) + 1\n",
    "test_gen = strip_labels(data_generator(test_data, batch_size=batch_size, target_size=input_size, shuffle=False, subfolder='test-jpg'))\n",
    "preds = model.predict_generator(test_gen, test_steps)\n",
    "preds = preds[:len(test_data)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "tpreds = preds > 0.16"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "with open('submission2.csv', 'w') as file:\n",
    "    file.write('image_name,tags\\n')\n",
    "    for img, pred in zip(test_files, tpreds):\n",
    "        indices = np.flatnonzero(pred)\n",
    "        tags = ' '.join([labels[i] for i in indices])\n",
    "        file.write('%s,%s\\n' % (img, tags))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.externals import joblib\n",
    "joblib.dump(preds, 'multilabel2405_128x128.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "preds = (joblib.load('multilabel2405_128x128.pkl') + joblib.load('multilabel2405.pkl')) / 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "tpreds = preds > 0.16"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "with open('submission3.csv', 'w') as file:\n",
    "    file.write('image_name,tags\\n')\n",
    "    for img, pred in zip(test_files, tpreds):\n",
    "        indices = np.flatnonzero(pred)\n",
    "        tags = ' '.join([labels[i] for i in indices])\n",
    "        file.write('%s,%s\\n' % (img, tags))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
